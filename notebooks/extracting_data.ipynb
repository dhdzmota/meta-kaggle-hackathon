{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6585aa-1e34-4415-b924-9bdd20edb0bb",
   "metadata": {},
   "source": [
    "# Notebook to extract data.\n",
    "In this notebook, we extract and organize information from all the datasets available in the UC Irvine Machine Learning Repository. This resource is widely used by researchers, educators, and practitioners as a benchmark collection for testing machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3982db4c-62e5-47e6-8b75-4349323c0995",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86177363-567d-4573-91eb-6813f8ce20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc4b2a0-6522-4a11-9f7d-24735d98bf33",
   "metadata": {},
   "source": [
    "### Constants and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97dd632c-1ab9-467f-b8bd-b4d11bc15243",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_void_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5b796b-1e8f-4705-85a7-e821a7429ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://archive.ics.uci.edu\"\n",
    "url = \"https://archive.ics.uci.edu/datasets?take=678&sort=desc&orderBy=NumHits&search=\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3bbbc4-a1ed-46cd-aef8-7b32d95791a7",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648ea71-b8b7-45cc-87bd-68400339d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_info(link):\n",
    "    \"\"\"\n",
    "    Extracts metadata from a dataset web page hosted on the UC Irvine Machine Learning Repository.\n",
    "\n",
    "    Parameters:\n",
    "    - link (str): URL of the dataset page to extract information from.\n",
    "\n",
    "    Returns:\n",
    "    - tuple:\n",
    "        - date (str or None): The date string found in the page header, if available.\n",
    "        - dataset_information (str or None): A combined string containing the dataset title,\n",
    "          subtitle, and descriptive information. If extraction fails, both values will be None.\n",
    "\n",
    "    Notes:\n",
    "    - If the extraction fails for any reason (e.g., invalid URL, page structure changes),\n",
    "      the function appends the link to a global list called `fill_void_info` for later review.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataset_response = requests.get(link)\n",
    "        dataset_soup = BeautifulSoup(dataset_response.content)\n",
    "        date = dataset_soup.find('h2').text\n",
    "        title = dataset_soup.find('h1').text\n",
    "        subtitle = dataset_soup.find('div', class_='relative flex flex-col gap-4 bg-base-100 p-4 shadow').text\n",
    "        info = dataset_soup.find('div', class_='p-4 pt-0').text\n",
    "        dataset_information = f\"\"\"{title} {subtitle} {info}\"\"\"\n",
    "        return date, dataset_information\n",
    "    except:\n",
    "        fill_void_info.append(link)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd7118-a448-4d9f-bafa-54a295421a9a",
   "metadata": {},
   "source": [
    "### Reading and processing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35ad9a0-72ea-4319-962e-8b56498c4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "response_text = response.text\n",
    "soup = BeautifulSoup(response_text)\n",
    "desiredlist = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebf0faa-619c-47a1-acf2-74d49e66bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_links_part = set(\n",
    "    [ref.get_attribute_list('href')[0] \n",
    "     for ref in desiredlist \n",
    "     if ref.get_attribute_list('href')[0].startswith('/dataset/')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbbd6a8-746b-4f35-a768-5789524cb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_links = [f'{main_url}{ref}' for ref in relevant_links_part]\n",
    "datasets_info = [get_link_info(link) for link in relevant_links]\n",
    "final_data = pd.DataFrame(datasets_info).rename(columns={0:'date', 1:'Total Description'}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1cddd2e-c5d1-41ef-a147-d4960a6c2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "final_data['date_dt'] = pd.to_datetime(final_data.date.str.replace('Donated on ', '').str.replace('Linked on ', ''))\n",
    "# Remove duplicate rows based on the 'Total Description' column to keep only unique entries\n",
    "final_data.drop_duplicates('Total Description', inplace=True)\n",
    "# Filter the data to only include entries from the year 2010 onward\n",
    "final_data = final_data[final_data.date_dt >= '2010']\n",
    "final_data.groupby(pd.Grouper(key='date_dt', freq='Y')).count().date.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dddbff6-d2f0-4a26-9118-44915b5d38e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "final_data.to_parquet('../data/external/UC_Irvine_ML_Repo.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
