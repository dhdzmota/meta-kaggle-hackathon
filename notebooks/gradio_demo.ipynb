{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed20df13-3508-4e97-92e8-f20d334aea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abed060-35e4-458f-9cad-c9cb4999767f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d45dbe3-10f2-4001-a91b-395cf008fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_non_negative(number):\n",
    "    if number < 0 : return 0\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f82122b9-f024-4dd7-bc49-7071bd19a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_pos(pos, value=0.1):\n",
    "    new_pos = {}\n",
    "    for node, position in pos.items():\n",
    "        new_position = position\n",
    "        new_position[1] = new_position[1] - value\n",
    "        new_pos[node] = new_position\n",
    "    return new_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f81273e-fe01-4fe5-9b0c-692d6aed86a9",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b4c5db-8a91-460a-8d54-3d2cfc7036ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg__user_dataset_relation_t__train = pd.read_parquet('../data/processed/train.parquet')\n",
    "agg__user_dataset_relation_t__test = pd.read_parquet('../data/processed/test.parquet')\n",
    "agg__user_dataset_relation_t__val = pd.read_parquet('../data/processed/val.parquet')\n",
    "\n",
    "user_dataset_relation_t = pd.read_parquet('../data/processed/UserDataset_relation_t.parquet')\n",
    "user_dataset_relation_oot = pd.read_parquet('../data/processed/UserDataset_relation_oot.parquet')\n",
    "\n",
    "reduced_dataset_versions = pd.read_parquet('../data/processed/reduced_dataset_versions.parquet')\n",
    "reduced_user_id = pd.read_parquet('../data/processed/reduced_user.parquet')\n",
    "df_users_followers_reduced = pd.read_parquet('../data/processed/reduced_user_followers.parquet')\n",
    "\n",
    "img_dataset = mpimg.imread('../assets/icons/dataset_icon2.png')\n",
    "img_user = mpimg.imread('../assets/icons/user_icon.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d8dab-203e-49fb-a809-4c0add120721",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff29c5b-cff7-4104-a763-3f7cf11fdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_user_lists = user_dataset_relation_t.groupby('UserId').DatasetId.apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab429e0-d365-40e0-af21-14b9f5589e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_user_id.set_index('UserId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c75a6fa-f2a7-436f-b4e4-5b85064b3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_to_compare_list = [\n",
    "    agg__user_dataset_relation_t__val,\n",
    "    agg__user_dataset_relation_t__test,\n",
    "    agg__user_dataset_relation_t__train\n",
    "]\n",
    "all_data_to_compare_df = pd.concat(all_data_to_compare_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1adfbe-69a3-4b06-826d-affa2176fe4e",
   "metadata": {},
   "source": [
    "## Computation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a131cd-3c16-41cc-b5b6-093be4ecadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SAMPLES = 20\n",
    "RANDOM_STATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c81a89d-5327-4335-bc75-26571003b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will generate the inital tags to select a user from 20 so the model recommends something.\n",
    "train_sample = agg__user_dataset_relation_t__train.sample(RANDOM_SAMPLES, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db1896f-b35a-446e-a0e9-2c3219bba6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_sample_list = reduced_user_id.index.intersection(train_sample.index.get_level_values(0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47eabae1-6930-44be-9f1c-c0983d4a4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_user = reduced_user_id.loc[user_id_sample_list].UserName.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2aa66f-4e5a-4d5e-a8ca-4573fbab7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets choose a threshold value for similarity. \n",
    "# If there is no max value we will say:\n",
    "# It seems you are to unique! \n",
    "# Then, we will recommend the most similar user (in the image), a list of ranked top 5 most similar users (dataframe).\n",
    "# The image will have associated (1 to 5) datasets, depending on the intersection and the recommended values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99d8caa7-a300-4909-8050-2bd8b0a62034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66e82ec-164e-41c4-a0d0-6bcb56f9df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_recommender_system('kalilurrahman', .38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce9ebc42-36b3-4f02-8168-c1ed48a19ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dataset_recommender_system(selected_user, similarity_threshold):\n",
    "    # From the user_ids identify the selected user.\n",
    "    one_sample_user_id = reduced_user_id[reduced_user_id.UserName == selected_user].index[0]\n",
    "    # Locate (in this case in the train dataset) the user.\n",
    "    one_sample = agg__user_dataset_relation_t__train.loc[one_sample_user_id].iloc[0]\n",
    "    # Determine all the previous datasets the user has seen. \n",
    "    already_seen_datasets = dataset_user_lists.loc[one_sample_user_id]\n",
    "\n",
    "    # Get all the information to compare with this user\n",
    "    all_data_to_compare_df_prev = all_data_to_compare_df[all_data_to_compare_df.VoteDate < one_sample.VoteDate]\n",
    "\n",
    "    # Compute the cosine distance with this user\n",
    "    all_res = all_data_to_compare_df_prev.drop(one_sample_user_id, level=0).embeddings.apply(\n",
    "        lambda x: (x * one_sample.embeddings).sum()\n",
    "    ).sort_values()\n",
    "\n",
    "    # Define a similarity threshold \n",
    "    all_res_sim = all_res[all_res > similarity_threshold]\n",
    "    all_res_sim = all_res_sim.loc[reduced_user_id.index.intersection(all_res_sim.index.get_level_values(0).tolist())]\n",
    "    top_users = all_res_sim.reset_index().drop_duplicates('UserId', keep='last').sort_values('embeddings')\n",
    "    renamed_columns={'level_1': 'corresponding_sets', 'embeddings': 'similarity'}\n",
    "    top5 = top_users.tail(5).rename(columns=renamed_columns).set_index(['UserId', 'corresponding_sets'])\n",
    "    \n",
    "    top5_info = all_data_to_compare_df.loc[top5.index]\n",
    "    top5_info['similarity'] = top5.similarity\n",
    "    top5_info.sort_values('similarity', ascending=False, inplace=True)\n",
    "    top5_info['Difference days'] = (one_sample.VoteDate - top5_info['VoteDate']).dt.days\n",
    "    top5_info['intersection_lists'] = top5_info.dataset_id.apply(lambda x: list(set(x).intersection(one_sample.dataset_id)))\n",
    "    top5_info['len_intersection_list'] = top5_info['intersection_lists'].apply(len)\n",
    "    top5_info['user_name'] = reduced_user_id.loc[top5_info.index.get_level_values(0)].UserName.to_list()\n",
    "    top5_info['display_name'] = reduced_user_id.loc[top5_info.index.get_level_values(0)].DisplayName.to_list()\n",
    "    top5_info = top5_info.sort_values(['len_intersection_list', 'similarity'], ascending=False)\n",
    "    top5_info['order_position'] = list(range(1, top5_info.shape[0]+1))\n",
    "    max_number_dataset_recommendation = 10\n",
    "    top5_info_datasets_recommendations = top5_info.dataset_id.explode().value_counts()\n",
    "    strong_recommendations = top5_info_datasets_recommendations[top5_info_datasets_recommendations > 1]\n",
    "    normal_recommendations = top5_info_datasets_recommendations[top5_info_datasets_recommendations == 1]\n",
    "    top_datasets_recommendations = strong_recommendations.head(max_number_dataset_recommendation).index.tolist()\n",
    "    try: \n",
    "        top_datasets_recommendations += normal_recommendations.sample(\n",
    "            transform_to_non_negative(max_number_dataset_recommendation-len(top_datasets_recommendations)), random_state=42\n",
    "        ).index.tolist()\n",
    "    except ValueError:\n",
    "        top_datasets_recommendations\n",
    "    \n",
    "    # quitar todos los datasets que el usuario ha visto en su vida para no\n",
    "    top_datasets_recommendations = list(set(top_datasets_recommendations)-set(already_seen_datasets))\n",
    "    user_node_id = one_sample_user_id\n",
    "    \n",
    "    G=nx.Graph()\n",
    "    G.add_node(user_node_id, image=img_user)\n",
    "    for dataset in top_datasets_recommendations:\n",
    "        G.add_node(dataset, image=img_dataset)\n",
    "        G.add_edge(dataset, user_node_id)\n",
    "    creator_user_id = reduced_dataset_versions.loc[top_datasets_recommendations].CreatorUserId.tolist()\n",
    "    recommended_datasets_df = reduced_user_id.loc[reduced_user_id.index.intersection(creator_user_id)].drop_duplicates('UserName').reset_index().merge(\n",
    "        reduced_dataset_versions.loc[top_datasets_recommendations].reset_index(), left_on='UserId', right_on='CreatorUserId', how='inner'\n",
    "    ).set_index('DatasetId')\n",
    "    \n",
    "    recommended_datasets_df['Created by'] = recommended_datasets_df['DisplayName'] + ' (' + recommended_datasets_df['UserName'] + ').'\n",
    "    recommended_datasets_df = recommended_datasets_df.drop(['CreatorUserId', 'UserId', 'UserName', 'DisplayName'], axis=1)\n",
    "\n",
    "    G2=nx.Graph()\n",
    "    for user in top5_info.index.get_level_values(0):\n",
    "        G2.add_node(user, image=img_user)\n",
    "    pos2 = {}\n",
    "    for i, node in enumerate(G2.nodes()):\n",
    "        pos2[node] = np.array([0, (len(G2.nodes())-(i+1))/len(G2.nodes())])\n",
    "\n",
    "    ## Plot User figure\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    nx.draw_networkx_edges(G2, pos2,ax=ax, alpha=0.5)\n",
    "    \n",
    "    trans = ax.transData.transform\n",
    "    trans2 = fig.transFigure.inverted().transform\n",
    "    piesize = 0.15 # this is the image size\n",
    "    p2 = piesize/2.0\n",
    "    x_move_position = 0.1\n",
    "    \n",
    "    for i, n in enumerate(G2):\n",
    "        xx, yy = trans(pos2[n]) # figure coordinates\n",
    "        xa, ya = trans2((xx,yy)) # axes coordinates\n",
    "        if not i: \n",
    "            scaler = 1.8\n",
    "            x_move = 0.25\n",
    "            fontsize = 20\n",
    "        a = plt.axes([xa-p2, ya-p2, scaler*piesize, scaler*piesize])\n",
    "        a.set_aspect('equal')\n",
    "        a.imshow(G2.nodes[n]['image'])\n",
    "        a.axis('off')\n",
    "        ax.text(pos2[n][0] + x_move, pos2[n][1], top5_info.loc[n].user_name.iloc[0], horizontalalignment='left', verticalalignment='center', fontsize=fontsize)\n",
    "        ax.text(pos2[n][0] - x_move_position, pos2[n][1], i+1, horizontalalignment='left', verticalalignment='center', fontsize=fontsize)\n",
    "        x_move = 0.1\n",
    "        scaler = 1\n",
    "        fontsize = 10\n",
    "\n",
    "    ax.axis('off')\n",
    "    ax.set_title('You might want to follow these users similar to you!')\n",
    "\n",
    "    # Plot dataset figure\n",
    "    pos = nx.spring_layout(G)\n",
    "    pos2 = modify_pos(pos, value=0.3)\n",
    "    min_max = pd.DataFrame(pos2).T.agg(['min', 'max'])\n",
    "    \n",
    "    fig_a = plt.figure(figsize=(5,5))\n",
    "    ax_a = plt.subplot(111)\n",
    "    ax_a.set_aspect('equal')\n",
    "    nx.draw_networkx_edges(G,pos,ax=ax_a, alpha=0.5)\n",
    "    \n",
    "    fig_lims=1.0\n",
    "    plt.xlim(min_max[0].iloc[0] - (0.3+0.05), min_max[0].iloc[1] + (0.3+0.05))\n",
    "    plt.ylim(min_max[1].iloc[0] - (0.3+0.05), min_max[1].iloc[1] + (0.3+0.05))\n",
    "    \n",
    "    trans = ax_a.transData.transform\n",
    "    trans2 = fig_a.transFigure.inverted().transform\n",
    "    piesize = 0.15 # this is the image size\n",
    "    p2 = piesize/2.0\n",
    "    for n in G:\n",
    "        xx,yy = trans(pos[n]) # figure coordinates\n",
    "        xa,ya = trans2((xx,yy)) # axes coordinates\n",
    "        a = plt.axes([xa-p2,ya-p2, piesize, piesize])\n",
    "        a.set_aspect('equal')\n",
    "        a.imshow(G.nodes[n]['image'])\n",
    "        a.axis('off')\n",
    "    nx.draw_networkx_labels(G, modify_pos(pos, value=0.3), ax=ax_a, font_size=8)\n",
    "    ax_a.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    final_users_recommendation = top5_info[['order_position', 'user_name', 'display_name', 'Difference days', 'similarity']]\n",
    "    final_dataset_recommendation = recommended_datasets_df.reset_index()\n",
    "    your_datasets_df = reduced_dataset_versions.loc[one_sample.dataset_id][['Title']]\n",
    "    if not top5_info.shape[0]:\n",
    "        text_output = f'There are no similar users with the given threshold ({similarity_threshold}), try another one or change the user.'\n",
    "    max_similarity = top5_info.similarity.max()\n",
    "    if  max_similarity > 0.9:\n",
    "        text_output = f'These users are similar with high confidence!'\n",
    "    elif max_similarity < 0.9 and max_similarity > 0.7:\n",
    "        text_output = f'These users are similar with some confidence!'\n",
    "    elif max_similarity < 0.7 and max_similarity > 0.5:\n",
    "        text_output = f'These users may or may-not be similar, do not trust that much!'\n",
    "    elif max_similarity < 0.5 and max_similarity > 0.3:\n",
    "        text_output = f'These users are randomly similar, do not trust that much.'\n",
    "    elif max_similarity < 0.3:\n",
    "        text_output = f'These users are not similar, do not trust the results.'\n",
    "    \n",
    "    return text_output, final_users_recommendation, fig, your_datasets_df, final_dataset_recommendation, fig_a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4feb15e-b693-4f01-b918-98261f4e66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dropdown = gr.Dropdown(choices=select_user, label=\"Choose a user\")\n",
    "similarity_threshold_slider = gr.Slider(minimum=0, maximum=1, value=0.7, label='Similarity Threshold (the bigger, the more similar)')\n",
    "recommended_users = gr.Dataframe(label='Recommended Users')\n",
    "recommended_users_fig = gr.Plot(label='')\n",
    "your_datasets = gr.Dataframe(label='These are the Datasets you liked:')\n",
    "recommended_datasets = gr.Dataframe(label='Recommended Datasets')\n",
    "recommended_datasets_fig = gr.Plot(label='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebbf9aee-8c0f-4aa6-b232-2c76b701139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* Running on public URL: https://b952e5080a135a4e76.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b952e5080a135a4e76.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5797/1656822897.py:129: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_5797/1656822897.py:129: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_5797/1656822897.py:71: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=(5,5))\n",
      "/tmp/ipykernel_5797/1656822897.py:129: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_5797/1656822897.py:129: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def run_recommender(user, threshold):\n",
    "    # Call your original function\n",
    "    comment, users, users_fig, liked, recommended, recommended_fig = dataset_recommender_system(user, threshold)\n",
    "\n",
    "    # Return each output with visibility enabled\n",
    "    return (\n",
    "        gr.update(value=comment, visible=True),\n",
    "        gr.update(value=users, visible=True),\n",
    "        gr.update(value=users_fig, visible=True),\n",
    "        gr.update(value=liked, visible=True),\n",
    "        gr.update(value=recommended, visible=True),\n",
    "        gr.update(value=recommended_fig, visible=True)\n",
    "    )\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Dataset Recommender System\")\n",
    "\n",
    "    # Inputs\n",
    "    user_dropdown = gr.Dropdown(choices=select_user, label=\"Choose a user\")\n",
    "    similarity_threshold_slider = gr.Slider(\n",
    "        minimum=0,\n",
    "        maximum=1,\n",
    "        value=0.7,\n",
    "        label='Select a Similarity Threshold (this is the minimum threshold a user may have to be similar to others: 0=Not Similar at all, 1=Equally Similar.)'\n",
    "    )\n",
    "    run_button = gr.Button(\"Run Recommender\")\n",
    "\n",
    "    # Outputs (initially hidden)\n",
    "    text_output = gr.Text(label='General comments...', visible=False)\n",
    "    recommended_users = gr.Dataframe(label='Recommended Users', visible=False)\n",
    "    recommended_users_fig = gr.Plot(label='', visible=False)\n",
    "    your_datasets = gr.Dataframe(label='These are the Datasets you liked:', visible=False)\n",
    "    recommended_datasets = gr.Dataframe(label='Recommended Datasets', visible=False)\n",
    "    recommended_datasets_fig = gr.Plot(label='', visible=False)\n",
    "\n",
    "    # Button triggers the wrapped function\n",
    "    run_button.click(\n",
    "        fn=run_recommender,\n",
    "        inputs=[user_dropdown, similarity_threshold_slider],\n",
    "        outputs=[\n",
    "            text_output,\n",
    "            recommended_users,\n",
    "            recommended_users_fig,\n",
    "            your_datasets,\n",
    "            recommended_datasets,\n",
    "            recommended_datasets_fig\n",
    "        ],\n",
    "        show_progress=True,\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a02504-78db-445a-b730-4b359279253b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
